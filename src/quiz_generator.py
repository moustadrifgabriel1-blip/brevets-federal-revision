"""
G√©n√©rateur de quiz bas√© sur l'IA pour le Brevet F√©d√©ral
G√©n√®re des questions vari√©es : QCM, Vrai/Faux, Texte √† trous, Calcul, Mise en situation
"""
import json
import random
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import google.generativeai as genai
import os


# Types de questions support√©s avec distribution pond√©r√©e
QUESTION_TYPES = {
    "qcm": {"label": "QCM (4 choix)", "weight": 35, "icon": "üìã"},
    "vrai_faux": {"label": "Vrai / Faux", "weight": 20, "icon": "‚úÖ"},
    "texte_trous": {"label": "Texte √† trous", "weight": 15, "icon": "‚úèÔ∏è"},
    "calcul": {"label": "Calcul", "weight": 15, "icon": "üî¢"},
    "mise_en_situation": {"label": "Mise en situation", "weight": 15, "icon": "üèóÔ∏è"},
}

# Modules o√π les questions de calcul sont pertinentes
CALCUL_MODULES = {"AA09", "AA10", "AA11", "AE05", "AE07"}


def evaluate_answer(question: Dict, user_answer) -> bool:
    """√âvalue si la r√©ponse de l'utilisateur est correcte, tous types confondus."""
    q_type = question.get('type', 'qcm')

    if user_answer is None:
        return False

    if q_type in ('qcm', 'mise_en_situation'):
        return user_answer == question.get('correct_answer')

    elif q_type == 'vrai_faux':
        return user_answer == question.get('correct_answer')

    elif q_type == 'texte_trous':
        acceptable = question.get('acceptable_answers', [str(question.get('correct_answer', ''))])
        user_clean = str(user_answer).strip().lower()
        return user_clean in [str(a).strip().lower() for a in acceptable]

    elif q_type == 'calcul':
        try:
            val = float(str(user_answer).replace(',', '.').strip())
            correct_val = float(question['correct_answer'])
            tolerance = question.get('tolerance', 0.02)
            if correct_val == 0:
                return abs(val) < 0.01
            return abs(val - correct_val) / abs(correct_val) <= tolerance
        except (ValueError, TypeError):
            return False

    return False


class QuizGenerator:
    """G√©n√®re des quiz interactifs bas√©s sur les concepts du Brevet F√©d√©ral"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gemini-3-pro-preview"):
        self.api_key = api_key or os.getenv('GOOGLE_API_KEY')
        self.model_name = model
        self.history_file = Path("data/quiz_history.json")
        self.model = None
        
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel(self.model_name)
    
    def generate_quiz(self, concepts: List[Dict], module: str = None, 
                     num_questions: int = 10, difficulty: str = "moyen",
                     weak_concept_ids: List[str] = None,
                     question_types: List[str] = None) -> Dict:
        """
        G√©n√®re un quiz √† partir des concepts
        
        Args:
            concepts: Liste des concepts √† tester
            module: Module sp√©cifique (ex: "AA01") ou None pour m√©lang√©
            num_questions: Nombre de questions √† g√©n√©rer
            difficulty: Niveau de difficult√© (facile, moyen, difficile)
            weak_concept_ids: IDs des concepts faibles √† prioriser (quiz adaptatif)
            question_types: Types de questions √† inclure (liste parmi QUESTION_TYPES.keys())
        
        Returns:
            Dict avec les questions et m√©tadonn√©es
        """
        # Filtrer par module si sp√©cifi√©
        filtered_concepts = concepts
        if module:
            filtered_concepts = [c for c in concepts if c.get('module') == module]
        
        if not filtered_concepts:
            return {"error": "Aucun concept trouv√© pour ce module"}
        
        # --- QUIZ ADAPTATIF : prioriser les concepts faibles ---
        if weak_concept_ids:
            weak_set = set(weak_concept_ids)
            weak_concepts = [c for c in filtered_concepts if c.get('id') in weak_set or c.get('name') in weak_set]
            other_concepts = [c for c in filtered_concepts if c.get('id') not in weak_set and c.get('name') not in weak_set]
            
            # Prendre ~60% des questions sur les concepts faibles
            num_weak = min(len(weak_concepts), int(num_questions * 0.6))
            num_other = min(len(other_concepts), num_questions - num_weak)
            
            selected_weak = random.sample(weak_concepts, num_weak) if weak_concepts else []
            selected_other = random.sample(other_concepts, num_other) if other_concepts else []
            selected = selected_weak + selected_other
            random.shuffle(selected)
        else:
            # S√©lection al√©atoire classique
            selected = random.sample(filtered_concepts, min(num_questions, len(filtered_concepts)))
        
        # G√©n√©rer les questions avec l'IA (types vari√©s)
        questions = []
        for i, concept in enumerate(selected, 1):
            question = self._generate_question(
                concept, difficulty, i,
                question_types=question_types,
                module=module
            )
            if question:
                questions.append(question)
        
        quiz = {
            "id": f"quiz_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "module": module or "Tous modules",
            "difficulty": difficulty,
            "num_questions": len(questions),
            "questions": questions,
            "created_at": datetime.now().isoformat()
        }
        
        return quiz
    
    def _generate_question(self, concept: Dict, difficulty: str, question_num: int,
                           question_types: List[str] = None, module: str = None) -> Optional[Dict]:
        """Dispatche vers le bon g√©n√©rateur selon le type de question choisi."""
        available_types = list(question_types) if question_types else list(QUESTION_TYPES.keys())

        # Calcul seulement pour modules techniques
        if module and module not in CALCUL_MODULES:
            available_types = [t for t in available_types if t != "calcul"]
        if not available_types:
            available_types = ["qcm"]

        # Choix pond√©r√© du type
        weights = [QUESTION_TYPES[t]["weight"] for t in available_types]
        chosen_type = random.choices(available_types, weights=weights, k=1)[0]

        generators = {
            "qcm": self._generate_qcm,
            "vrai_faux": self._generate_vrai_faux,
            "texte_trous": self._generate_texte_trous,
            "calcul": self._generate_calcul,
            "mise_en_situation": self._generate_mise_en_situation,
        }

        generator = generators.get(chosen_type, self._generate_qcm)
        question = generator(concept, difficulty, question_num)

        if question:
            question["type"] = chosen_type
        return question

    # --- Utilitaires internes ---

    def _parse_ai_response(self, response) -> Dict:
        """Parse et nettoie la r√©ponse JSON de l'IA."""
        text = response.text.strip()
        if text.startswith("```json"):
            text = text.replace("```json", "").replace("```", "").strip()
        elif text.startswith("```"):
            text = text.replace("```", "").strip()
        return json.loads(text)

    def _add_metadata(self, data: Dict, concept: Dict, question_num: int) -> Dict:
        """Ajoute les m√©tadonn√©es du concept."""
        data["concept_id"] = concept.get('id')
        data["concept_name"] = concept.get('name')
        data["question_num"] = question_num
        return data

    # --- G√©n√©rateurs par type ---

    def _generate_qcm(self, concept: Dict, difficulty: str, question_num: int) -> Optional[Dict]:
        """G√©n√®re une question QCM classique (4 choix)."""
        try:
            prompt = f"""G√©n√®re une question √† choix multiples (QCM) pour le Brevet F√©d√©ral.

**Concept :** {concept.get('name', 'N/A')}
**Description :** {concept.get('description', 'N/A')}
**Difficult√© :** {difficulty}

R√©ponds en JSON strict :
{{
  "question": "Question claire et pr√©cise",
  "options": ["Option A", "Option B", "Option C", "Option D"],
  "correct_answer": 0,
  "explanation": "Explication d√©taill√©e"
}}

IMPORTANT : correct_answer = INDEX (0-3). En fran√ßais. Distracteurs plausibles."""

            response = self.model.generate_content(prompt)
            data = self._parse_ai_response(response)
            return self._add_metadata(data, concept, question_num)
        except Exception as e:
            print(f"Erreur QCM: {e}")
            return self._generate_fallback(concept, question_num, "qcm")

    def _generate_vrai_faux(self, concept: Dict, difficulty: str, question_num: int) -> Optional[Dict]:
        """G√©n√®re une question Vrai/Faux."""
        try:
            prompt = f"""G√©n√®re une affirmation VRAI ou FAUX pour le Brevet F√©d√©ral.

**Concept :** {concept.get('name', 'N/A')}
**Description :** {concept.get('description', 'N/A')}
**Difficult√© :** {difficulty}

R√©ponds en JSON strict :
{{
  "question": "Affirmation compl√®te √† √©valuer comme vraie ou fausse",
  "correct_answer": true,
  "explanation": "Explication d√©taill√©e de pourquoi c'est vrai/faux"
}}

IMPORTANT : correct_answer est un bool√©en (true ou false). L'affirmation doit √™tre technique et pr√©cise. En fran√ßais."""

            response = self.model.generate_content(prompt)
            data = self._parse_ai_response(response)
            # S'assurer que correct_answer est bien un bool
            data['correct_answer'] = bool(data['correct_answer'])
            return self._add_metadata(data, concept, question_num)
        except Exception as e:
            print(f"Erreur Vrai/Faux: {e}")
            return self._generate_fallback(concept, question_num, "vrai_faux")

    def _generate_texte_trous(self, concept: Dict, difficulty: str, question_num: int) -> Optional[Dict]:
        """G√©n√®re une question √† texte √† trous."""
        try:
            prompt = f"""G√©n√®re une question √† TEXTE √Ä TROUS pour le Brevet F√©d√©ral.

**Concept :** {concept.get('name', 'N/A')}
**Description :** {concept.get('description', 'N/A')}
**Difficult√© :** {difficulty}

R√©ponds en JSON strict :
{{
  "question": "Phrase avec un _____ √† compl√©ter (un seul trou)",
  "correct_answer": "mot ou expression correcte",
  "acceptable_answers": ["r√©ponse1", "r√©ponse2", "variante3"],
  "explanation": "Explication d√©taill√©e"
}}

IMPORTANT :
- Le trou est marqu√© par _____ dans la question
- correct_answer = la r√©ponse principale (un mot ou courte expression)
- acceptable_answers = liste de toutes les r√©ponses acceptables (synonymes, variantes)
- Le mot √† trouver doit √™tre un terme technique important. En fran√ßais."""

            response = self.model.generate_content(prompt)
            data = self._parse_ai_response(response)
            # S'assurer que acceptable_answers contient aussi correct_answer
            if data.get('correct_answer') not in data.get('acceptable_answers', []):
                data.setdefault('acceptable_answers', []).append(data['correct_answer'])
            return self._add_metadata(data, concept, question_num)
        except Exception as e:
            print(f"Erreur texte √† trous: {e}")
            return self._generate_fallback(concept, question_num, "texte_trous")

    def _generate_calcul(self, concept: Dict, difficulty: str, question_num: int) -> Optional[Dict]:
        """G√©n√®re une question de calcul (modules techniques : √©lectro, m√©ca, math)."""
        try:
            prompt = f"""G√©n√®re une question de CALCUL pour le Brevet F√©d√©ral (√©lectrotechnique/m√©canique/math√©matique).

**Concept :** {concept.get('name', 'N/A')}
**Description :** {concept.get('description', 'N/A')}
**Difficult√© :** {difficulty}

R√©ponds en JSON strict :
{{
  "question": "√ânonc√© du probl√®me avec toutes les donn√©es num√©riques",
  "correct_answer": 42.5,
  "tolerance": 0.02,
  "unit": "Œ©",
  "explanation": "D√©veloppement complet du calcul √©tape par √©tape"
}}

IMPORTANT :
- correct_answer = valeur num√©rique (nombre, pas de texte)
- tolerance = marge d'erreur relative accept√©e (0.02 = 2%)
- unit = unit√© de mesure (V, A, Œ©, W, m, kg, N, etc.)
- La question doit inclure toutes les donn√©es n√©cessaires au calcul
- L'explication doit montrer CHAQUE √âTAPE du calcul. En fran√ßais."""

            response = self.model.generate_content(prompt)
            data = self._parse_ai_response(response)
            # S'assurer que correct_answer est num√©rique
            data['correct_answer'] = float(data['correct_answer'])
            data.setdefault('tolerance', 0.02)
            data.setdefault('unit', '')
            return self._add_metadata(data, concept, question_num)
        except Exception as e:
            print(f"Erreur calcul: {e}")
            return self._generate_fallback(concept, question_num, "calcul")

    def _generate_mise_en_situation(self, concept: Dict, difficulty: str, question_num: int) -> Optional[Dict]:
        """G√©n√®re une question de mise en situation professionnelle (QCM avec sc√©nario)."""
        try:
            prompt = f"""G√©n√®re une question de MISE EN SITUATION pour le Brevet F√©d√©ral Sp√©cialiste de R√©seau.

**Concept :** {concept.get('name', 'N/A')}
**Description :** {concept.get('description', 'N/A')}
**Difficult√© :** {difficulty}

R√©ponds en JSON strict :
{{
  "scenario": "Description d√©taill√©e d'une situation professionnelle r√©elle (2-3 phrases)",
  "question": "Question concr√®te li√©e au sc√©nario",
  "options": ["Action A", "Action B", "Action C", "Action D"],
  "correct_answer": 0,
  "explanation": "Explication d√©taill√©e avec r√©f√©rence aux normes/bonnes pratiques"
}}

IMPORTANT :
- Le sc√©nario d√©crit une situation de terrain (chantier, maintenance, incident...)
- correct_answer = INDEX (0-3) de la bonne r√©ponse
- Les options sont des ACTIONS concr√®tes que le professionnel pourrait entreprendre
- En fran√ßais."""

            response = self.model.generate_content(prompt)
            data = self._parse_ai_response(response)
            return self._add_metadata(data, concept, question_num)
        except Exception as e:
            print(f"Erreur mise en situation: {e}")
            return self._generate_fallback(concept, question_num, "mise_en_situation")

    # --- Fallback ---

    def _generate_fallback(self, concept: Dict, question_num: int, q_type: str = "qcm") -> Dict:
        """G√©n√®re une question de secours si l'IA √©choue, adapt√©e au type demand√©."""
        name = concept.get('name', 'inconnu')
        desc = concept.get('description', 'Description du concept')[:100]

        if q_type == "vrai_faux":
            return self._add_metadata({
                "question": f"Le concept '{name}' est fondamental pour le Brevet F√©d√©ral.",
                "correct_answer": True,
                "explanation": f"'{name}' fait partie des comp√©tences requises.",
                "fallback": True,
            }, concept, question_num)

        elif q_type == "texte_trous":
            return self._add_metadata({
                "question": f"Le concept _____ se d√©finit comme : {desc}.",
                "correct_answer": name,
                "acceptable_answers": [name, name.lower()],
                "explanation": f"La r√©ponse est '{name}'.",
                "fallback": True,
            }, concept, question_num)

        elif q_type == "calcul":
            return self._add_metadata({
                "question": f"Si R1 = 10 Œ© et R2 = 20 Œ© sont en s√©rie, quelle est la r√©sistance totale ?",
                "correct_answer": 30.0,
                "tolerance": 0.01,
                "unit": "Œ©",
                "explanation": "En s√©rie : Rtotal = R1 + R2 = 10 + 20 = 30 Œ©",
                "fallback": True,
            }, concept, question_num)

        elif q_type == "mise_en_situation":
            return self._add_metadata({
                "scenario": f"Vous √™tes responsable d'un chantier impliquant '{name}'.",
                "question": f"Quelle est la premi√®re action √† entreprendre concernant '{name}' ?",
                "options": [
                    f"V√©rifier les normes relatives √† {name}",
                    "Commencer les travaux imm√©diatement",
                    "D√©l√©guer sans v√©rification",
                    "Reporter l'intervention",
                ],
                "correct_answer": 0,
                "explanation": f"La v√©rification des normes est toujours la premi√®re √©tape pour {name}.",
                "fallback": True,
            }, concept, question_num)

        else:  # qcm par d√©faut
            return self._add_metadata({
                "question": f"Que repr√©sente le concept '{name}' ?",
                "options": [desc, "Une autre d√©finition non li√©e", "Un concept diff√©rent", "Aucune de ces r√©ponses"],
                "correct_answer": 0,
                "explanation": f"La bonne r√©ponse d√©crit correctement {name}.",
                "fallback": True,
            }, concept, question_num)
    
    def save_quiz_result(self, quiz_id: str, score: int, total: int, 
                        time_spent: int, answers: List[Dict]):
        """Sauvegarde le r√©sultat d'un quiz dans l'historique"""
        history = self._load_history()
        
        result = {
            "quiz_id": quiz_id,
            "score": score,
            "total": total,
            "percentage": (score / total * 100) if total > 0 else 0,
            "time_spent": time_spent,
            "answers": answers,
            "completed_at": datetime.now().isoformat()
        }
        
        history.append(result)
        self._save_history(history)
    
    def _load_history(self) -> List[Dict]:
        """Charge l'historique des quiz"""
        if self.history_file.exists():
            with open(self.history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    
    def _save_history(self, history: List[Dict]):
        """Sauvegarde l'historique des quiz"""
        self.history_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)
    
    def get_history(self, limit: int = 10) -> List[Dict]:
        """Retourne l'historique des derniers quiz"""
        history = self._load_history()
        return sorted(history, key=lambda x: x['completed_at'], reverse=True)[:limit]
    
    def get_stats(self) -> Dict:
        """Calcule les statistiques globales des quiz"""
        history = self._load_history()
        
        if not history:
            return {
                "total_quizzes": 0,
                "average_score": 0,
                "best_score": 0,
                "total_time": 0,
                "total_questions": 0
            }
        
        return {
            "total_quizzes": len(history),
            "average_score": sum(q['percentage'] for q in history) / len(history),
            "best_score": max(q['percentage'] for q in history),
            "total_time": sum(q.get('time_spent', 0) for q in history),
            "total_questions": sum(q['total'] for q in history)
        }
